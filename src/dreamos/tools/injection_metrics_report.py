#!/usr/bin/env python3
"""
Injection Metrics Report

This script analyzes the injection_attempts.json file generated by the CursorInjector
hybrid injection method and generates a report on injection performance.
"""

import json
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict
import statistics
import sys

def parse_args():
    parser = argparse.ArgumentParser(description="Generate injection metrics report")
    parser.add_argument("--metrics-file", type=str, default="runtime/logs/injection_attempts.json",
                        help="Path to the injection metrics JSON file")
    parser.add_argument("--output", type=str, default=None,
                        help="Output file path for the report (default: stdout)")
    parser.add_argument("--days", type=int, default=1,
                        help="Number of days to include in the report (default: 1)")
    return parser.parse_args()

def load_metrics(file_path):
    """Load the metrics from the JSON file."""
    try:
        with open(file_path, "r") as f:
            data = json.load(f)
        return data.get("attempts", [])
    except (json.JSONDecodeError, FileNotFoundError) as e:
        print(f"Error loading metrics file: {e}", file=sys.stderr)
        return []

def filter_recent_metrics(metrics, days):
    """Filter metrics to only include those from the last N days."""
    if not metrics:
        return []
        
    cutoff_date = datetime.now() - timedelta(days=days)
    recent_metrics = []
    
    for entry in metrics:
        try:
            timestamp = datetime.strptime(entry["timestamp"], "%Y-%m-%d %H:%M:%S")
            if timestamp >= cutoff_date:
                recent_metrics.append(entry)
        except (KeyError, ValueError):
            # Skip entries with invalid timestamps
            continue
            
    return recent_metrics

def generate_report(metrics):
    """Generate a statistical report from the metrics."""
    if not metrics:
        return "No metrics data available."
        
    # Group metrics by agent and method
    by_agent = defaultdict(list)
    by_method = defaultdict(list)
    
    # Overall statistics
    total_attempts = len(metrics)
    successful_attempts = sum(1 for m in metrics if m.get("successful", False))
    total_chars = sum(m.get("chars", 0) for m in metrics)
    
    # Performance metrics
    if successful_attempts > 0:
        avg_chars_per_second = sum(m.get("chars_per_second", 0) for m in metrics if m.get("successful", False)) / successful_attempts
    else:
        avg_chars_per_second = 0
    
    # Collect metrics by agent and method
    for entry in metrics:
        agent_id = entry.get("agent_id", "unknown")
        method = entry.get("method", "unknown")
        
        by_agent[agent_id].append(entry)
        by_method[method].append(entry)
    
    # Calculate success rates
    success_rate_overall = (successful_attempts / total_attempts) * 100 if total_attempts > 0 else 0
    
    # Format the report
    report = [
        "## Injection Metrics Report",
        f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "### Overall Statistics",
        f"Total injection attempts: {total_attempts}",
        f"Successful attempts: {successful_attempts} ({success_rate_overall:.2f}%)",
        f"Total characters injected: {total_chars}",
        f"Average injection speed: {avg_chars_per_second:.2f} chars/second",
        "",
        "### By Injection Method",
    ]
    
    # Add method statistics
    for method, entries in by_method.items():
        method_attempts = len(entries)
        method_successful = sum(1 for m in entries if m.get("successful", False))
        method_success_rate = (method_successful / method_attempts) * 100 if method_attempts > 0 else 0
        
        if method_successful > 0:
            method_speeds = [m.get("chars_per_second", 0) for m in entries if m.get("successful", False)]
            method_avg_speed = sum(method_speeds) / len(method_speeds)
            if len(method_speeds) > 1:
                method_speed_stddev = statistics.stdev(method_speeds)
            else:
                method_speed_stddev = 0
        else:
            method_avg_speed = 0
            method_speed_stddev = 0
            
        report.append(f"#### {method.capitalize()}")
        report.append(f"- Attempts: {method_attempts}")
        report.append(f"- Success rate: {method_success_rate:.2f}%")
        report.append(f"- Average speed: {method_avg_speed:.2f} chars/second (Â±{method_speed_stddev:.2f})")
        report.append("")
    
    # Add agent statistics
    report.append("### By Agent")
    
    for agent_id, entries in sorted(by_agent.items()):
        agent_attempts = len(entries)
        agent_successful = sum(1 for m in entries if m.get("successful", False))
        agent_success_rate = (agent_successful / agent_attempts) * 100 if agent_attempts > 0 else 0
        agent_methods = {m.get("method", "unknown") for m in entries}
        
        report.append(f"#### {agent_id}")
        report.append(f"- Attempts: {agent_attempts}")
        report.append(f"- Success rate: {agent_success_rate:.2f}%")
        report.append(f"- Methods used: {', '.join(sorted(agent_methods))}")
        report.append("")
    
    return "\n".join(report)

def main():
    args = parse_args()
    metrics_file = Path(args.metrics_file)
    
    if not metrics_file.exists():
        print(f"Metrics file not found: {metrics_file}", file=sys.stderr)
        sys.exit(1)
        
    metrics = load_metrics(metrics_file)
    recent_metrics = filter_recent_metrics(metrics, args.days)
    
    report = generate_report(recent_metrics)
    
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w") as f:
            f.write(report)
        print(f"Report written to {output_path}")
    else:
        print(report)

if __name__ == "__main__":
    main() 