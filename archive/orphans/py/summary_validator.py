import json\nimport os\nimport datetime\nimport re\nfrom collections import Counter\n\n# --- Configuration ---\nSUMMARY_LOG_FILENAME = \"summary_log.jsonl\"\nREAUDIT_REPORT_FILENAME = \"summary_reaudit_report.jsonl\"\nQUALITY_ALERT_FLAG_FILENAME = \"summary_quality_alert.flag\"\nSTATUS_LOG_FILENAME = \"summary_validator_status.log\" # Separate status log\n\nREAD_LINES_LIMIT = 100\nWEAKNESS_THRESHOLD = 0.7\nALERT_THRESHOLD_PERCENT = 10.0\n\n# --- Heuristics Configuration ---
VAGUE_WORDS = [\"may\", \"possibly\", \"perhaps\", \"could\", \"might\", \"seems\", \"appears\"]\nSHORT_PREVIEW_THRESHOLD = 20 # Length below which preview is considered weak\nREPETITION_THRESHOLD = 0.6 # Jaccard index threshold for adjacent similarity\n\n# --- Helper Functions ---
def get_current_timestamp():\n    return datetime.datetime.now(datetime.timezone.utc).isoformat()\n\ndef log_validator_status(status_log_path, message):\n    timestamp = get_current_timestamp()\n    try:\n        with open(status_log_path, \'a\') as f:\n            f.write(f\"[{timestamp}] {message}\\n\")\n        print(f\"[VALIDATOR_STATUS] {message}\\n\")\n    except Exception as e:\n        print(f\"[VALIDATOR_ERROR] Failed to write to status log {status_log_path}: {e}\")\n\ndef calculate_jaccard_similarity(text1, text2):\n    \"\"\"Calculates Jaccard similarity between the word sets of two texts.\"\"\"\n    set1 = set(text1.lower().split())\n    set2 = set(text2.lower().split())\n    intersection = len(set1.intersection(set2))\n    union = len(set1.union(set2))\n    return intersection / union if union > 0 else 0\n\ndef score_summary_weakness(summary_data, previous_summary_data):\n    \"\"\"Calculates a heuristic weakness score for a summary entry.\"\"\"\n    score = 0.0\n    reasons = []\n    preview = summary_data.get(\'preview\', \'\')\n\n    # 1. Check for vague phrasing\n    vague_word_count = sum(1 for word in VAGUE_WORDS if word in preview.lower())\n    if vague_word_count > 0:\n        score += 0.2 * vague_word_count # Add score per vague word\n        reasons.append(f\"{vague_word_count} vague words found\")\n\n    # 2. Check for short preview\n    if len(preview) < SHORT_PREVIEW_THRESHOLD:\n        score += 0.3\n        reasons.append(f\"Preview length ({len(preview)}) below threshold ({SHORT_PREVIEW_THRESHOLD})\")\n\n    # 3. Check for repetition with previous entry\n    if previous_summary_data:\n        prev_preview = previous_summary_data.get(\'preview\', \'\')\n        similarity = calculate_jaccard_similarity(preview, prev_preview)\n        if similarity > REPETITION_THRESHOLD:\n            score += 0.4 * similarity # Score based on similarity degree\n            reasons.append(f\"High similarity ({similarity:.2f}) with previous entry\")\n\n    # 4. Low trust score bonus weakness points\n    trust_score = summary_data.get(\'summary_trust_score\', 1.0)\n    if trust_score < 0.5:\n        score += (1.0 - trust_score) * 0.2 # Add more points for lower trust\n        reasons.append(f\"Low trust score ({trust_score:.1f})\")\n\n    # Clamp score between 0.0 and 1.0\n    score = max(0.0, min(1.0, score))\n    return score, reasons\n\n# --- Main Logic ---
if __name__ == \"__main__\":\n    workspace_root = os.getcwd()\n    script_dir = os.path.join(workspace_root, \"sandbox/ironvale_stream_watcher\") # Use same dir\n\n    summary_log_path_abs = os.path.join(script_dir, SUMMARY_LOG_FILENAME)\n    reaudit_report_path_abs = os.path.join(script_dir, REAUDIT_REPORT_FILENAME)\n    quality_alert_flag_path_abs = os.path.join(script_dir, QUALITY_ALERT_FLAG_FILENAME)\n    status_log_path_abs = os.path.join(script_dir, STATUS_LOG_FILENAME)\n\n    os.makedirs(script_dir, exist_ok=True)\n\n    log_validator_status(status_log_path_abs, \"Ironvale Summary Validator starting.\")\n\n    # Read last N lines from summary log\n    summary_entries = []\n    try:\n        if os.path.exists(summary_log_path_abs):\n            with open(summary_log_path_abs, \'r\') as f:\n                all_lines = f.readlines()\n                start_index = max(0, len(all_lines) - READ_LINES_LIMIT)\n                log_validator_status(status_log_path_abs, f\"Reading from line {start_index + 1} of {summary_log_path_abs}\")\n                for i, line in enumerate(all_lines[start_index:], start=start_index):\n                    try:\n                        summary_entries.append(json.loads(line))\n                    except json.JSONDecodeError:\n                        log_validator_status(status_log_path_abs, f\"WARN: Skipping invalid JSON on line {i + 1} in {summary_log_path_abs}\")\n        else:\n            log_validator_status(status_log_path_abs, f\"Summary log file not found: {summary_log_path_abs}. Nothing to validate.\")\n            summary_entries = [] # Ensure it's empty\n\n    except Exception as e:\n        log_validator_status(status_log_path_abs, f\"ERROR: Failed to read {summary_log_path_abs}: {e}\")\n        summary_entries = [] # Ensure it's empty on error\n\n    total_entries_read = len(summary_entries)\n    log_validator_status(status_log_path_abs, f\"Read {total_entries_read} entries from summary log.\")\n\n    weak_entries_count = 0\n    previous_entry = None\n\n    # Clear or prepare reaudit report\n    try:\n        with open(reaudit_report_path_abs, \'w\') as f:\n            f.write(f\"# Summary Reaudit Report - {get_current_timestamp()}\\n\")\n            f.write(f\"# Threshold Score: {WEAKNESS_THRESHOLD}\\n# Entries Analyzed: {total_entries_read}\\n\\n\")\n    except Exception as e:\n        log_validator_status(status_log_path_abs, f\"ERROR: Failed to initialize reaudit report {reaudit_report_path_abs}: {e}\")\n        exit(1)\n\n    # Analyze entries\n    for entry in summary_entries:\n        score, reasons = score_summary_weakness(entry, previous_entry)\n\n        if score > WEAKNESS_THRESHOLD:\n            weak_entries_count += 1\n            log_validator_status(status_log_path_abs, f\"Flagged weak entry (Score: {score:.2f}): {entry.get(\'preview\', \'N/A\')}\")\n            try:\n                with open(reaudit_report_path_abs, \'a\') as f:\n                    report_entry = {\n                        \"flagged_timestamp\": get_current_timestamp(),\n                        \"original_timestamp\": entry.get(\'timestamp\'),\n                        \"gpt_log_timestamp\": entry.get(\'gpt_log_timestamp\'),\n                        \"weakness_score\": score,\n                        \"reasons\": reasons,\n                        \"preview\": entry.get(\'preview\'),\n                        \"response_hash\": entry.get(\'response_hash\')\n                    }\n                    f.write(json.dumps(report_entry) + \'\\n\')\n            except Exception as e:\n                log_validator_status(status_log_path_abs, f\"ERROR: Failed to write to reaudit report: {e}\")\n\n        previous_entry = entry # Update for next iteration\n\n    log_validator_status(status_log_path_abs, f\"Validation complete. Found {weak_entries_count} weak entries out of {total_entries_read}.\")\n\n    # Check alert threshold\n    if total_entries_read > 0:\n        weak_percentage = (weak_entries_count / total_entries_read) * 100\n        log_validator_status(status_log_path_abs, f\"Weak entry percentage: {weak_percentage:.2f}%\")\n        if weak_percentage > ALERT_THRESHOLD_PERCENT:\n            log_validator_status(status_log_path_abs, f\"ALERT: Weak summary percentage ({weak_percentage:.2f}%) exceeds threshold ({ALERT_THRESHOLD_PERCENT}%). Creating quality alert flag.\")\n            if not os.path.exists(quality_alert_flag_path_abs):\n                 try:\n                     with open(quality_alert_flag_path_abs, \'w\') as f:\n                         f.write(f\"Summary quality alert triggered at {get_current_timestamp()} ({weak_percentage:.2f}% weak)\\n\")\n                 except Exception as e:\
                      log_validator_status(status_log_path_abs, f\"ERROR: Failed to create quality alert flag: {e}\")\n            else:\n                 log_validator_status(status_log_path_abs, \"Quality alert flag already exists.\")\n    else:\n        log_validator_status(status_log_path_abs, \"No entries analyzed, skipping alert check.\")\n\n    log_validator_status(status_log_path_abs, \"Ironvale Summary Validator finished.\")
